{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIGITAL SIGNAL PROCESSING and DEEP-LEARNING\n",
    "============================================\n",
    "\n",
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "- DSP/Audio Features for ML: [Valerio Velardo](https://www.youtube.com/watch?v=rlypsap6Wow&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=8)\n",
    "- [DSP: Basics](https://support.ircam.fr/docs/AudioSculpt/3.0/co/Sampling.html) - Aliasing, Nyquist Freq.,lowest detectable frequency\n",
    "- A signal sampled with a 32 KHz SR, any freq. components > 16 KHz (N.F.), we get an aliasing\n",
    "- Nyquist Frequency and the relation between sampling-rate and max. frequency\n",
    "    - $F_{max} = Sampling Rate/2$\n",
    "    - $F_{max}$ is called _Nyquist Frequency_\n",
    "- Wav length (size) of np array = SR * duration of clip\n",
    "\n",
    "**Sound perception**: - [link](http://physics.bu.edu/~duffy/py105/Sound.html), [link](https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2013.00636.x)\n",
    "- We perceive sound lograthimically\n",
    "- **Weber-Fechner law**: Above a minimal threshold of perception $S_0$, perceived intensity $P$ is logarithmic to stimulus intensity $S$: $P = K. log (\\frac{S}{S_0})$\n",
    "\n",
    "### Time domain features\n",
    "\n",
    "- Amplitude Envelope\n",
    "- RMS Energy\n",
    "\n",
    "\n",
    "### FFT\n",
    "\n",
    "- $s(t) = A_1.sin(2\\pi.f_1.t + \\phi_1) + A_2.sin(2\\pi.f_2.t + \\phi_2) + \\ldots{}$ \n",
    "- FFT: Y-axis: Magnitude, X-Axis: Freq.\n",
    "- Plotting a sine wave using freqs. [link](https://stackoverflow.com/questions/22566692/python-how-to-plot-graph-sine-wave)\n",
    "- When plotted - it shows a reflection around Nyquist Frequency = SR/2.\n",
    "- Reflection = aliasing\n",
    "\n",
    "### STFT\n",
    "\n",
    "- Compute FFT at several intervals \n",
    "- Interval = Frame length\n",
    "- Preserves time domain even though it is a freq. transformation!!\n",
    "- SSFT gives **Spectorgram**\n",
    "- 3 axes\n",
    "- Y: Freq., X: Time, Color variation: Magnitude\n",
    "\n",
    "\n",
    "### Mel Frequency Cepstral Coefficients (MFCC)\n",
    "\n",
    "- Timbral/textural features of sound\n",
    "- _Frequency_ domain feature\n",
    "- Approx. _human_ auditory system\n",
    "- 13-40 coeffs.\n",
    "- Calc. at each _frame_\n",
    "- Humans are able to detect piano vs violin playing same pitch/freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
